{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225a79fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134.73s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.13/site-packages (2.11.7)\n",
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.13/site-packages (1.11.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (3.12.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./venv/lib/python3.13/site-packages (from pydantic) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.13/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langchain-community pydantic faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6420b6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings # Or any other embedding model you prefer\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import Ollama # The LLM import\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "#Load Json\n",
    "with open('products1.json', 'r',encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# loader = JSONLoader(file_path='./products_data.json', jq_schema='.', text_content=False)\n",
    "# data = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(data)} documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eff6602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 processed documents from product data.\n",
      "Number of chunks after splitting: 4\n"
     ]
    }
   ],
   "source": [
    "# 2. Document Preprocessing and Chunking\n",
    "\n",
    "# The JSONLoader might load the entire JSON as a single document or multiple.\n",
    "# For better retrieval, we want to break down the information into smaller, meaningful chunks.\n",
    "# For this specific JSON structure, it's better to iterate and create documents for each product.\n",
    "\n",
    "processed_documents = []\n",
    "for taxonomy_product_entry in data:\n",
    "    taxonomy_product_name = taxonomy_product_entry.get(\"taxonomyProductName\", \"N/A\")\n",
    "    taxonomy_product_id = taxonomy_product_entry.get(\"taxonomyProductId\", \"N/A\")\n",
    "\n",
    "    for product in taxonomy_product_entry.get(\"products\", []):\n",
    "        product_name = product.get(\"productName\", \"N/A\")\n",
    "        product_id = product.get(\"productId\", \"N/A\")\n",
    "        product_sme = product.get(\"productSmeName\", \"N/A\")\n",
    "\n",
    "        # Create a detailed string for each product\n",
    "        content = (\n",
    "            f\"Taxonomy Product ID: {taxonomy_product_id}\\n\"\n",
    "            f\"Taxonomy Product Name: {taxonomy_product_name}\\n\"\n",
    "            f\"Product ID: {product_id}\\n\"\n",
    "            f\"Product Name: {product_name}\\n\"\n",
    "            f\"Product SME: {product_sme}\\n\"\n",
    "        )\n",
    "        \n",
    "        # Add components if they exist\n",
    "        components = product.get(\"components\", [])\n",
    "        if components:\n",
    "            content += \"Components:\\n\"\n",
    "            for comp in components:\n",
    "                content += f\"  - ID: {comp.get('componentID', 'N/A')}, Name: {comp.get('componentName', 'N/A')}\\n\"\n",
    "\n",
    "        # Add market segments if they exist\n",
    "        market_segments = product.get(\"marketSegments\", [])\n",
    "        if market_segments:\n",
    "            content += \"Market Segments:\\n\"\n",
    "            for segment in market_segments:\n",
    "                content += (\n",
    "                    f\"  - Segment Name: {segment.get('marketSegmentName', 'N/A')}\\n\"\n",
    "                    f\"    Availability: {segment.get('productAvailability', 'N/A')}\\n\"\n",
    "                    f\"    Status: {segment.get('status', 'N/A')}\\n\"\n",
    "                    f\"    Membership Types: {', '.join(segment.get('membershipTypes', []))}\\n\"\n",
    "                )\n",
    "        \n",
    "        # Create a LangChain Document object for each product\n",
    "        from langchain.docstore.document import Document\n",
    "        processed_documents.append(Document(page_content=content, metadata={\"product_id\": product_id, \"product_name\": product_name}))\n",
    "\n",
    "print(f\"Created {len(processed_documents)} processed documents from product data.\")\n",
    "# Example of a processed document\n",
    "# print(\"\\nExample Processed Document:\")\n",
    "# print(processed_documents[0].page_content)\n",
    "\n",
    "# Using a Text Splitter (even though our docs are already per-product, it's good practice)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "chunks = text_splitter.split_documents(processed_documents)\n",
    "print(f\"Number of chunks after splitting: {len(chunks)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86451a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAISS vector store...\n",
      "FAISS vector store created.\n"
     ]
    }
   ],
   "source": [
    "# 3. Create Embeddings and Vector Store\n",
    "\n",
    "# Initialize your embedding model (e.g., Ollama, OpenAIEmbeddings, HuggingFaceEmbeddings)\n",
    "# For Ollama, ensure you have Ollama running and a model pulled (e.g., 'llama2')\n",
    "# Example: ollama run llama2\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # You can change to other models like \"nomic-embed-text\" or \"mxbai-embed-large\" for better performance\n",
    "\n",
    "# Create a FAISS vector store from the document chunks\n",
    "print(\"Creating FAISS vector store...\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "print(\"FAISS vector store created.\")\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87cea4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set up the RAG Chain\n",
    "\n",
    "# Initialize your Language Model (LLM)\n",
    "# For Ollama, ensure it's running\n",
    "llm = Ollama(model=\"llama2\") # Or \"mistral\", \"gemma\", etc.\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "You are a helpful assistant for product information. Use the following context to answer the user's question.\n",
    "If you don't know the answer, just say that you don't have enough information to answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Construct the RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a5539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chatbot Ready ---\n",
      "Type 'exit' to quit.\n",
      "Bot: Hello! I'm happy to help you with any questions you may have about the products listed in the documents you provided. Could you please specify which product you are interested in, or provide more context about what you are looking for?\n",
      "\n",
      "Bot:  Thank you for providing the context! Based on the documents provided, I can see that there are three different products mentioned: DiabetesManagementProgram, LiverManagementProgram, and HeartManagementProgram.\n",
      "\n",
      "Unfortunately, I don't have enough information to answer your question about the Diabetes Management Program as the document you provided does not mention this specific product. The document only mentions two products: LiverManagementProgram and HeartManagementProgram.\n",
      "\n",
      "Could you please provide more context or clarify which product you are referring to? I'll do my best to help you with the information available.\n",
      "\n",
      "Bot:  Thank you for providing me with the context. Based on the documents provided, I can see that NewManagementProgram is a product with a product ID of 6757 and a product name of \"NewManagementProgram.\" The document with the highest confidence score is the one with the ID 'db2940fd-ab81-4c3a-9202-6c246c92e18c', which contains information about the components of NewManagementProgram.\n",
      "\n",
      "According to the document, the components of NewManagementProgram are:\n",
      "\n",
      "* ID: 10, Name: ABC\n",
      "* ID: 34, Name: HHF\n",
      "\n",
      "Therefore, the answer to your question is \"ABC and HHF.\"\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mType \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to quit.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     user_query = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m user_query.lower() == \u001b[33m'\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGoodbye!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/workspace/ml/chatbot/venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/workspace/ml/chatbot/venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 5. Ask Questions!\n",
    "\n",
    "print(\"\\n--- Chatbot Ready ---\")\n",
    "print(\"Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"You: \")\n",
    "    if user_query.lower() == 'exit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    response = rag_chain.invoke(user_query)\n",
    "    print(f\"Bot: {response}\\n\")\n",
    "\n",
    "\n",
    "# Example Queries you can try:\n",
    "# - What is the Diabetes Management Program?\n",
    "# - Tell me about the LiverManagementProgram.\n",
    "# - What are the components of NewManagementProgram?\n",
    "# - Which programs are available for the 'Employer' market segment with 'Medicaid' membership type?\n",
    "# - Who is the SME for HeartManagementProgram?\n",
    "# - Do you have information about a product with ID 42424?\n",
    "# - What are the membership types for the DiabetesManagementProgram?\n",
    "# - What is the status of the LiverManagementProgram?\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
